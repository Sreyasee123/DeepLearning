{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33PVQCWAFJKf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "# Download and extract the dataset\n",
        "!wget https://www.dropbox.com/s/4jw31k5mlzcmgis/genres.tar.gz?dl=0 -O genres.tar.gz\n",
        "!tar -xvf genres.tar.gz\n",
        "\n",
        "# Set the path to the dataset\n",
        "DATASET_PATH = 'genres'\n",
        "\n",
        "# Define genres\n",
        "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n",
        "          'metal', 'pop', 'reggae', 'rock']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_spectrogram(audio_path, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "    return S_dB\n",
        "\n",
        "def resize_spectrogram(spectrogram, target_shape):\n",
        "    \"\"\"Resize spectrogram to target shape.\"\"\"\n",
        "    spectrogram = librosa.util.fix_length(spectrogram, size=target_shape[1], axis=1)\n",
        "    return spectrogram\n",
        "\n",
        "def preprocess_data(dataset_path, genres, target_size=(128, 128)):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    for genre in genres:\n",
        "        genre_folder = os.path.join(dataset_path, genre)\n",
        "        for filename in os.listdir(genre_folder):\n",
        "            file_path = os.path.join(genre_folder, filename)\n",
        "            spectrogram = audio_to_spectrogram(file_path)\n",
        "            # Resize the spectrogram\n",
        "            spectrogram = resize_spectrogram(spectrogram, target_shape=(128, 128))\n",
        "            spectrograms.append(spectrogram)\n",
        "            labels.append(genre)\n",
        "\n",
        "    return np.array(spectrograms), np.array(labels)\n",
        "\n",
        "# Load and preprocess data\n",
        "spectrograms, labels = preprocess_data(DATASET_PATH, GENRES)\n",
        "\n",
        "# Normalize and reshape data\n",
        "spectrograms = np.array([np.expand_dims(s, axis=-1) for s in spectrograms])  # Add channel dimension\n",
        "spectrograms = spectrograms / np.max(spectrograms)  # Normalize\n",
        "\n",
        "# Encode labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(GENRES)\n",
        "one_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(spectrograms, one_hot_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "4oCLkEChFPks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow/Keras imports\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the 2D CNN model\n",
        "def build_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "input_shape = (spectrograms.shape[1], spectrograms.shape[2], 1)  # (height, width, channels)\n",
        "model = build_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Lucubn4FXm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'model' is your trained model and 'X_test' is your test set\n",
        "# Make predictions\n",
        "y_pred_proba = model.predict(X_test)  # Get probabilities from the model\n",
        "y_pred_classes = np.argmax(y_pred_proba, axis=1)  # Convert probabilities to class indices\n",
        "\n",
        "# Convert one-hot encoded labels to class indices\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Define genres\n",
        "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n",
        "          'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "# Calculate and print precision, recall, and F1-score\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=GENRES)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "J0mcduPmFbou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}